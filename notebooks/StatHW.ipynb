{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3429df3-f0c2-4a43-9eb1-e8f8813e44d9",
   "metadata": {},
   "source": [
    "# Mathematical Statistics Homework Assignment\n",
    "## RichÃ¡rd Kiss - KAYXFT - 2023.05"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eda3007-0192-474b-b23b-e0190b7ffe21",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "In this assignment I use a dataset that was generated as part of my PhD research topic. The dataset contains music playlists and song recommendations for these playlists generated with two different algorithms. In this assignment I am performing statistical analysis to compare these two algorithms in terms of recommendation performance.\n",
    "\n",
    "## The two recommendation algorithms\n",
    "### Algorithm 1.\n",
    "The first algorithm recommends songs based solely on their popularity. It consistently returns the top $K$ most popular songs, irrespective of the particular songs present in the playlist for which we are making new song recommendations. Despite its simplicity, this approach is very effective and often used as a benchmark in the evaluation of recommendation systems.\n",
    "\n",
    "### Algorithm 2.\n",
    "The second algorithm employs Skip-Gram with negative sampling to learn insightful, low-dimensional song representations (denoted by $w_i \\in \\mathbb{R}^l$ for all songs $i$, where $l$ is the dimensionality of the representation). The core concept revolves around discerning whether song pairs originate from the original data distribution, $P_{orig}$, or from a synthetic noise distribution, $P_{noise}$.\n",
    "\n",
    "The song pairs in the original distribution are generated by sampling songs from a playlist within a specific context window (of size $c$), and corresponding noise samples are created by randomly pairing songs that do not appear together within a context window (of the same size $c$).\n",
    "\n",
    "To reduce computational demands, we ease the restriction of never appearing together. Since the co-appearance graph of songs is usually sparse, choosing two random songs seldom results in a pair that co-appears in the dataset. Although there's still a slim chance, this compromise generally speeds up the sampling process without drastically affecting the results. (You can find more details about this method  [here](https://www.baeldung.com/cs/nlps-word2vec-negative-sampling)).\n",
    "\n",
    "Once we've learned the song representations $w$, we can use them to generate playlist recommendations. The process begins by selecting the $K$ most similar songs for each song in the playlist. Then, we count the number of times a particular song appears within the $K$ proximity of each song in the playlist and rank them in descending order. Finally, we return the top $K$ songs from this sorted list.\n",
    "\n",
    "\n",
    "## The data\n",
    "spotify dataset, #>30, some basic statistics (num songs, albums, artists etc.)\n",
    "\n",
    "\n",
    "# Stati\n",
    "## The data I use in this notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "caa69006-40ea-4398-80bb-cafb1ac6e81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import scipy.stats as stats"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
