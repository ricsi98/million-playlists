{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ac9a239-3026-4f90-ba72-23ccb10e549e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx\n",
    "import geoopt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import random\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f784301-0bc3-400e-8ec7-b29e0b59704b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m \u001b[0mgeoopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanifolds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPoincareBall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearnable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m     \n",
       "Poincare ball model.\n",
       "\n",
       "See more in :doc:`/extended/stereographic`\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "c : float|tensor\n",
       "    ball's negative curvature. The parametrization is constrained to have positive c\n",
       "\n",
       "Notes\n",
       "-----\n",
       "It is extremely recommended to work with this manifold in double precision\n",
       "\n",
       "\n",
       "See Also\n",
       "--------\n",
       ":class:`Stereographic`\n",
       ":class:`StereographicExact`\n",
       ":class:`PoincareBallExact`\n",
       ":class:`SphereProjection`\n",
       ":class:`SphereProjectionExact`\n",
       "\u001b[0;31mInit docstring:\u001b[0m Initializes internal Module state, shared by both nn.Module and ScriptModule.\n",
       "\u001b[0;31mFile:\u001b[0m           ~/.venvs/base/lib/python3.10/site-packages/geoopt/manifolds/stereographic/manifold.py\n",
       "\u001b[0;31mType:\u001b[0m           ABCMeta\n",
       "\u001b[0;31mSubclasses:\u001b[0m     PoincareBallExact"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "geoopt.manifolds.PoincareBall?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2ea1dc03-f713-45b4-94da-136111ad39e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ManifoldEmbedding(nn.Module):\n",
    "    \n",
    "    def __init__(self, manifold, num_embeddings, embedding_dim, dtype=torch.double, requires_grad=True, weights=None):\n",
    "        super().__init__()\n",
    "        if dtype != torch.double:\n",
    "            logging.warning(\"Double precision is recommended for embeddings on manifold\")\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.num_embeddings = num_embeddings\n",
    "        self._manifold = manifold\n",
    "        if weights is None:\n",
    "            data = torch.zeros((num_embeddings, embedding_dim), dtype=dtype)\n",
    "            self.w = geoopt.ManifoldParameter(data, requires_grad=requires_grad, manifold=self._manifold)\n",
    "            self.reset_parameters()\n",
    "        else:\n",
    "            raise NotImplementedError()\n",
    "            \n",
    "    def forward(self, x):\n",
    "        s0 = x.shape\n",
    "        ws = self.w[x.view(-1)]\n",
    "        return ws.view(*s0, self.embedding_dim)\n",
    "    \n",
    "    def reset_parameters(self) -> None:\n",
    "        nn.init.normal_(self.w.data, std=0.25)\n",
    "        self.w.data[:] = self._manifold.retr(torch.zeros(self.embedding_dim), self.w.data)\n",
    "        \n",
    "        \n",
    "class PoincareEmbedding(ManifoldEmbedding):\n",
    "    \n",
    "    def __init__(self, num_embeddings, embedding_dim, c=1.0, **kwargs):\n",
    "        manifold = geoopt.manifolds.PoincareBall(c, learnable=False)\n",
    "        super().__init__(manifold, num_embeddings, embedding_dim, **kwargs)\n",
    "        \n",
    "        \n",
    "class ManifoldSquaredDistance(nn.Module):\n",
    "    \n",
    "    def __init__(self, manifold):\n",
    "        super().__init__()\n",
    "        self.manifold = manifold\n",
    "        \n",
    "    def forward(self, a, b):\n",
    "        return self.manifold.dist2(a,b)\n",
    "    \n",
    "    \n",
    "class SGNSLoss(nn.Module):\n",
    "    \n",
    "    def __init__(self, reduction=\"mean\"):\n",
    "        super().__init__()\n",
    "        self.reduction = reduction\n",
    "        \n",
    "    def forward(self, d2, y):\n",
    "        y.masked_fill_(y == 0, -1)\n",
    "        loss = torch.log(torch.sigmoid(d2 * (-y)))\n",
    "        if self.reduction is None:\n",
    "            return -loss\n",
    "        elif self.reduction == \"mean\":\n",
    "            return -loss.mean()\n",
    "        elif self.rediction == \"sum\":\n",
    "            return -loss.sum()\n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9ff5326b-3757-477b-887d-b6cda07e0617",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightning as pl\n",
    "\n",
    "\n",
    "class Model(pl.LightningModule):\n",
    "    \n",
    "    def __init__(self, num_embeddings, embedding_dim, k=1.0):\n",
    "        super().__init__()\n",
    "        self.embd = PoincareEmbedding(num_embeddings, embedding_dim, k)\n",
    "        self.d2 = ManifoldSquaredDistance(embd._manifold)\n",
    "        self.loss_fn = SGNSLoss()\n",
    "        \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        print(x.shape, y.mean())\n",
    "        e1, e2 = x[:, 0], x[:, 1]\n",
    "        v1, v2 = self.embd(e1), self.embd(e2)\n",
    "        d2 = self.d2(v1, v2)\n",
    "        loss = self.loss_fn(d2, y)\n",
    "        print(loss.item())\n",
    "        self.log(\"training_loss\", loss.item(), prog_bar=True)\n",
    "        return loss\n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = geoopt.optim.RiemannianAdam(self.parameters(), 1e-3)\n",
    "        return optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c2e3acce-b021-4c7d-96ec-dffa5771f5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from itertools import accumulate\n",
    "\n",
    "def skip_gram(x, i, w):\n",
    "    return x[i], x[max(0, i-w):i] + x[i+1:i+w+1]\n",
    "\n",
    "class SkipGramWithNegativeSampling:\n",
    "    \n",
    "    def __init__(self, window, vocabulary, negative=5, negative_probs=None):\n",
    "        self.window = window\n",
    "        self.vocabulary = vocabulary\n",
    "        self.negative = negative\n",
    "        if negative_probs is not None:\n",
    "            self.negative_probs = list(accumulate(negative_probs))\n",
    "        else:\n",
    "            self.negative_probs = None\n",
    "        \n",
    "    def sample_negatives(self, query):\n",
    "        if self.negative == 0:\n",
    "            return []\n",
    "        items = set(query)\n",
    "        randoms = random.choices(self.vocabulary, k=len(items)*self.negative, cum_weights=self.negative_probs)\n",
    "        return zip(list(items)*self.negative, randoms)\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        grams = [skip_gram(x, i, self.window) for i in range(len(x))]\n",
    "        batches = [[w,c] for w,context in grams for c in context]\n",
    "        negatives = list(self.sample_negatives(x))\n",
    "        labels = [1] * len(batches) + [0] * len(negatives)\n",
    "        return batches + negatives, labels\n",
    "    \n",
    "    \n",
    "class ToTensor:\n",
    "    \n",
    "    def __init__(self, *dtypes):\n",
    "        self.dtypes = dtypes\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        assert isinstance(x, tuple)\n",
    "        assert len(x) == len(self.dtypes), f\"Number of inputs {len(x)} does not match number of specified data types {len(self.dtypes)}\"\n",
    "        return tuple(torch.tensor(xi, dtype=di) for xi, di in zip(x, self.dtypes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8ed4bd85-16a7-4b2d-bc0a-1f178c971eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"../src/\")\n",
    "from models.transformer.loader import PlaylistDataset\n",
    "from models.transformer.transform import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "209a8071-36b0-49d6-8dd0-29247a512369",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# utils to create this file list\n",
    "\n",
    "def get_file_list(base):\n",
    "    return [os.path.join(base, f) for f in os.listdir(base) if \".json\" in f]\n",
    "\n",
    "files = get_file_list(\"../data/processed/\")\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "359aedff-066d-44c2-ae37-8aca5409e0e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "281217"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "MIN_FREQ = 15\n",
    "\n",
    "with open(\"../data/frequencies.json\") as f:\n",
    "    frequencies = json.load(f)\n",
    "\n",
    "frequencies = dict(filter(lambda item: item[1] >= MIN_FREQ, frequencies.items()))\n",
    "songs = list(set(frequencies.keys()))\n",
    "song2idx = {s: i for i,s in enumerate(songs)}\n",
    "idx2song = {i: s for s,i in song2idx.items()}\n",
    "len(frequencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ff49438f-406c-4a9a-941b-0c956af54abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(data):\n",
    "    pairs, labels = list(zip(*data))\n",
    "    return torch.cat(pairs, dim=0), torch.cat(labels, dim=0)\n",
    "\n",
    "# probs\n",
    "alpha = 0.75\n",
    "adjusted_song_weights = np.array([frequencies[s]**alpha for s in song2idx.keys()])\n",
    "\n",
    "\n",
    "tf = Compose(\n",
    "    RemoveUnknownTracks(songs),\n",
    "    TrackURI2Idx(song2idx),\n",
    "    SkipGramWithNegativeSampling(5, list(song2idx.values()), 10, negative_probs=adjusted_song_weights),\n",
    "    ToTensor(torch.long, torch.float)\n",
    ")\n",
    "\n",
    "dataset = PlaylistDataset(files, 50_000, transform=tf)\n",
    "loader = torch.utils.data.DataLoader(dataset, batch_size=2, collate_fn=collate_fn, num_workers=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d19a85bc-52fe-4573-b5ba-86a632343729",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EMBEDDING = len(songs)\n",
    "EMBEDDING_DIM = 32\n",
    "THETA = 3\n",
    "\n",
    "model = Model(NUM_EMBEDDING, EMBEDDING_DIM, THETA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "54004572-f0f7-46d4-bd22-d5966eaf2335",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16ac40e-6e25-4c10-a900-10baeca53c4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name    | Type                    | Params\n",
      "----------------------------------------------------\n",
      "0 | embd    | PoincareEmbedding       | 9.0 M \n",
      "1 | d2      | ManifoldSquaredDistance | 1     \n",
      "2 | loss_fn | SGNSLoss                | 0     \n",
      "----------------------------------------------------\n",
      "9.0 M     Trainable params\n",
      "2         Non-trainable params\n",
      "9.0 M     Total params\n",
      "35.996    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee6202f946dd4b338af4b783291c5f60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5620, 2]) tensor(0.4982)\n",
      "2.1158828101975757\n",
      "torch.Size([430, 2]) tensor(0.4419)\n",
      "1.9365777741379142\n",
      "torch.Size([1000, 2]) tensor(0.4700)\n",
      "2.041391946547476\n",
      "torch.Size([4760, 2]) tensor(0.4958)\n",
      "2.1232267549794526\n",
      "torch.Size([4170, 2]) tensor(0.4940)\n",
      "2.097162534012782\n",
      "torch.Size([2250, 2]) tensor(0.4889)\n",
      "2.0847246248830715\n",
      "torch.Size([320, 2]) tensor(0.4062)\n",
      "1.7389213962627443\n",
      "torch.Size([2960, 2]) tensor(0.4899)\n",
      "2.0763438357831623\n",
      "torch.Size([3620, 2]) tensor(0.4972)\n",
      "2.1191803129590845\n",
      "torch.Size([4080, 2]) tensor(0.4926)\n",
      "2.1022303911109863\n",
      "torch.Size([1590, 2]) tensor(0.4906)\n",
      "2.084970279897508\n",
      "torch.Size([3740, 2]) tensor(0.5000)\n",
      "2.1177839828562774\n",
      "torch.Size([1390, 2]) tensor(0.4820)\n",
      "2.0462985446344737\n",
      "torch.Size([1940, 2]) tensor(0.4845)\n",
      "2.0790010134866144\n",
      "torch.Size([2420, 2]) tensor(0.4876)\n",
      "2.069303238998115\n",
      "torch.Size([2420, 2]) tensor(0.4876)\n",
      "2.0719898407321455\n",
      "torch.Size([1810, 2]) tensor(0.4972)\n",
      "2.1293263006469645\n",
      "torch.Size([3620, 2]) tensor(0.4917)\n",
      "2.086537512831321\n",
      "torch.Size([1880, 2]) tensor(0.5000)\n",
      "2.1312951881617974\n",
      "torch.Size([580, 2]) tensor(0.4483)\n",
      "1.9281462944850283\n",
      "torch.Size([1060, 2]) tensor(0.4717)\n",
      "1.99539193587687\n",
      "torch.Size([3950, 2]) tensor(0.4962)\n",
      "2.1205887876285345\n",
      "torch.Size([3140, 2]) tensor(0.4936)\n",
      "2.1162995953898465\n",
      "torch.Size([3330, 2]) tensor(0.4955)\n",
      "2.1238889770066627\n",
      "torch.Size([1700, 2]) tensor(0.4824)\n",
      "2.06029943655782\n",
      "torch.Size([6220, 2]) tensor(0.4952)\n",
      "2.1011537237448734\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7444a884-879c-4c14-9d8f-fbb359534102",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
