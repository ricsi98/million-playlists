{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "43aa9099-6d18-4bcc-bed1-d0d6414032ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import TransformerEncoderLayer, TransformerEncoder, Embedding\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7e82888-c488-4b72-9b13-68c3ff7f56af",
   "metadata": {},
   "outputs": [],
   "source": [
    "wv = Word2Vec.load(\"../checkpoints/model_final.model\").wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "80341712-c11f-4d8e-83c9-27d4b48559e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 281217\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0990,  2.4085,  0.3983,  ...,  0.0845,  0.2064,  2.6756],\n",
       "        [ 0.2235,  5.3773,  2.8357,  ..., -4.8849, -5.0111, -2.0209],\n",
       "        [-2.7695,  4.5329,  0.3006,  ..., -5.3204, -3.4041,  0.4088],\n",
       "        ...,\n",
       "        [-1.1284, -0.0572, -2.2218,  ..., -0.6975,  0.8115, -1.0279],\n",
       "        [ 0.6771,  0.1054,  0.1341,  ...,  0.6022, -0.1027, -0.7091],\n",
       "        [-0.8491, -0.9734, -1.2336,  ...,  0.8185, -0.1867, -1.1534]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create embedding layer from gensim embeddings\n",
    "print(wv.vector_size, len(wv))\n",
    "embd = Embedding(len(wv), wv.vector_size)\n",
    "embd.weight.data.copy_(torch.tensor(wv.vectors, dtype=torch.float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "0ea9c7ca-6488-402a-b9b6-6e1486aafbd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_layer = TransformerEncoderLayer(wv.vector_size, 10, batch_first=True)\n",
    "encoder = TransformerEncoder(encoder_layer, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "a244aeea-7524-47da-b7a3-a7ed9fd22dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = random.choices(list(wv.key_to_index.keys()), k=12)\n",
    "t_seq = torch.tensor([wv.key_to_index[item] for item in seq], dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "78f6b777-e40d-484f-98b8-be3316023744",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 12, 100]), torch.Size([1, 12, 100]))"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = embd(t_seq.view(1,-1))\n",
    "encoder(v).shape, v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "06af6187-1540-49a8-9d0c-bd81261cccd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 12, 100])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "ea28195e-c0c7-4109-bc7f-bc6830a81a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask padding: src_key_padding_mask\n",
    "# mask some items: mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "d5caf656-addf-41f5-beff-abdc180e5630",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False, False,  True, False,  True],\n",
       "        [False, False,  True, False,  True],\n",
       "        [False, False,  True, False,  True],\n",
       "        [False, False,  True, False,  True],\n",
       "        [False, False,  True, False,  True]])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_attn_mask(seq_mask):\n",
    "    \"\"\"\n",
    "        If a BoolTensor is provided, positions with True are not allowed \n",
    "        to attend while False values will be unchanged.\n",
    "        Softmax goes along -1 dimension\n",
    "    \"\"\"\n",
    "    n = seq_mask.shape[-1]\n",
    "    mask = torch.zeros((n,n), dtype=torch.bool)\n",
    "    mask[:, seq_mask.nonzero()] = True\n",
    "    return mask\n",
    "    \n",
    "mask = generate_attn_mask(torch.Tensor([False, False, True, False, True]))\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "286bdf66-19a7-4f38-935a-6e68f93343de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10, 12, 12]), torch.Size([1, 12, 100]))"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = torch.Tensor([False] * v.shape[1])\n",
    "attn_mask = generate_attn_mask(mask).repeat(10,1,1)\n",
    "attn_mask.shape, v.shape, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "d8d36ab2-1f13-41d6-a491-919ee16c196e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_mask.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "cd8b0f2e-8a17-465e-aea2-529bf2da94cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0812, -0.1265, -0.8604,  ..., -0.1958,  2.6957,  1.0880],\n",
       "         [ 0.2169, -0.0378, -0.5093,  ...,  0.4028,  3.0029,  0.0229],\n",
       "         [ 2.4005,  0.4884, -0.8056,  ...,  0.4309,  0.6416, -0.3111],\n",
       "         ...,\n",
       "         [ 2.2272,  0.7680,  0.0664,  ...,  0.4633,  0.1944, -0.7390],\n",
       "         [ 1.7706,  0.5730, -1.4109,  ...,  0.1600,  1.1616, -0.4409],\n",
       "         [ 1.9712, -0.0155, -1.8148,  ...,  0.3185,  1.3445, -0.2619]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = encoder(v, mask=attn_mask)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "64d4c616-62ca-43a4-8011-fa48e10333d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "\n",
    "class PlaylistDataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, files, playlist_per_file, transform=None):\n",
    "        self.files = files\n",
    "        self.current_file_index = -1\n",
    "        self.data = None\n",
    "        self.ppf = playlist_per_file\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.ppf * self.files\n",
    "    \n",
    "    def _load(self, path):\n",
    "        with open(path, \"r\") as f:\n",
    "            self.data = json.load(f)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        file_index = index // self.ppf\n",
    "        offset = index % self.ppf\n",
    "        if self.current_file_index != file_index:\n",
    "            logging.debug(f\"Loading file {self.files[file_index]}\")\n",
    "            self._load(self.files[file_index])\n",
    "            self.current_file_index = file_index\n",
    "        tracks = self.data[\"playlists\"][offset]\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            tracks = self.transform(tracks)\n",
    "        \n",
    "        return tracks\n",
    "\n",
    "    \n",
    "class Compose:\n",
    "    \n",
    "    def __init__(self, *tfs):\n",
    "        self.tfs = tfs\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        for tf in self.tfs:\n",
    "            x = tf(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "class RemoveUnknownTracks:\n",
    "    \n",
    "    def __init__(self, known_tracks):\n",
    "        kt = known_tracks\n",
    "        if not isinstance(kt, set):\n",
    "            kt = set(kt)\n",
    "        self.kt = kt\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        return [xi for xi in x if xi in self.kt]\n",
    "    \n",
    "    \n",
    "class TrackURI2Idx:\n",
    "    \n",
    "    def __init__(self, uri2idx, offset=0):\n",
    "        self.offset = offset\n",
    "        self.uri2idx = uri2idx\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        return [self.uri2idx[xi] + self.offset for xi in x]\n",
    "    \n",
    "    \n",
    "class ToLongTensor:\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        return torch.LongTensor(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "439e89b4-6aaf-4f77-8cae-7336214af09e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../playlists_data/chunk_0.json',\n",
       " '../playlists_data/chunk_1.json',\n",
       " '../playlists_data/chunk_2.json',\n",
       " '../playlists_data/chunk_3.json',\n",
       " '../playlists_data/chunk_4.json',\n",
       " '../playlists_data/chunk_5.json',\n",
       " '../playlists_data/chunk_6.json',\n",
       " '../playlists_data/chunk_7.json',\n",
       " '../playlists_data/chunk_8.json',\n",
       " '../playlists_data/chunk_9.json',\n",
       " '../playlists_data/chunk_10.json',\n",
       " '../playlists_data/chunk_11.json',\n",
       " '../playlists_data/chunk_12.json',\n",
       " '../playlists_data/chunk_13.json',\n",
       " '../playlists_data/chunk_14.json',\n",
       " '../playlists_data/chunk_15.json',\n",
       " '../playlists_data/chunk_16.json',\n",
       " '../playlists_data/chunk_17.json',\n",
       " '../playlists_data/chunk_18.json',\n",
       " '../playlists_data/chunk_19.json']"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = [f\"../playlists_data/chunk_{i}.json\" for i in range(20)]\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "32ec579d-0321-4bab-a02a-8b0f5db81953",
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = Compose(\n",
    "    RemoveUnknownTracks(wv.key_to_index.keys()),\n",
    "    TrackURI2Idx(wv.key_to_index),\n",
    "    ToLongTensor()\n",
    ")\n",
    "\n",
    "ds = PlaylistDataset(files, 50000, transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "4405cde0-ed89-4b0b-ad0b-9ff0457fa9db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████| 1000000/1000000 [00:45<00:00, 22163.16it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(1_000_000), total=1_000_000):\n",
    "    ds[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "de558937-34a7-41c5-8ee9-913b47437201",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|██                                       | 49/1000 [00:07<02:02,  7.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ../playlists_data/chunk_0.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████                                     | 99/1000 [00:16<02:36,  5.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ../playlists_data/chunk_1.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█████▉                                  | 149/1000 [00:26<02:18,  6.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ../playlists_data/chunk_2.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|███████▉                                | 199/1000 [00:36<01:57,  6.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ../playlists_data/chunk_3.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|█████████▉                              | 249/1000 [00:46<01:56,  6.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ../playlists_data/chunk_4.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███████████▉                            | 299/1000 [00:56<01:53,  6.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ../playlists_data/chunk_5.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|█████████████▉                          | 349/1000 [01:06<02:38,  4.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ../playlists_data/chunk_6.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███████████████▉                        | 399/1000 [01:16<01:41,  5.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ../playlists_data/chunk_7.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|█████████████████▉                      | 449/1000 [01:27<01:39,  5.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ../playlists_data/chunk_8.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|███████████████████▉                    | 499/1000 [01:36<01:20,  6.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ../playlists_data/chunk_9.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████████████████████▉                  | 549/1000 [01:46<01:18,  5.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ../playlists_data/chunk_10.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|███████████████████████▉                | 599/1000 [01:56<01:07,  5.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ../playlists_data/chunk_11.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|█████████████████████████▉              | 649/1000 [02:06<00:58,  5.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ../playlists_data/chunk_12.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████████████████████████▉            | 699/1000 [02:16<00:52,  5.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ../playlists_data/chunk_13.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|█████████████████████████████▉          | 749/1000 [02:27<00:43,  5.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ../playlists_data/chunk_14.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████████████████████████████▉        | 799/1000 [02:36<00:49,  4.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ../playlists_data/chunk_15.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|█████████████████████████████████▉      | 849/1000 [02:46<00:25,  5.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ../playlists_data/chunk_16.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|███████████████████████████████████▉    | 899/1000 [02:57<00:18,  5.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ../playlists_data/chunk_17.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████████████████████████████████▉  | 949/1000 [03:07<00:10,  5.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ../playlists_data/chunk_18.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████▉| 999/1000 [03:17<00:00,  5.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ../playlists_data/chunk_19.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 1000/1000 [03:18<00:00,  5.03it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "BATCH_SIZE = 50000\n",
    "\n",
    "def get_playlists(data):\n",
    "    for plist in data[\"playlists\"]:\n",
    "        sequence = [song[\"track_uri\"] for song in plist[\"tracks\"]]\n",
    "        yield sequence\n",
    "\n",
    "def dump(batch, path):\n",
    "    print(f\"Writing {path}\")\n",
    "    with open(path, \"w\") as f:\n",
    "        json.dump({\"playlists\": batch}, f)\n",
    "        \n",
    "batch = []\n",
    "i = 0\n",
    "for fname in tqdm(list(sorted(os.listdir(\"../data\")))):\n",
    "    if not (fname.startswith(\"mpd.slice.\") and fname.endswith(\".json\")):\n",
    "        continue\n",
    "        \n",
    "    fullpath = os.sep.join((\"../data\", fname))\n",
    "    with open(fullpath, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    batch += list(get_playlists(data))\n",
    "    \n",
    "    if len(batch) >= BATCH_SIZE:\n",
    "        dump(batch, f\"../playlists_data/chunk_{i}.json\")\n",
    "        batch = []\n",
    "        i += 1\n",
    "        \n",
    "if len(batch) > 0:\n",
    "    dump(batch, f\"../playlists_data/chunk_{i}.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f099e0f-aa9a-404b-856b-49fc884a775a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
