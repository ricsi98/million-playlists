{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43aa9099-6d18-4bcc-bed1-d0d6414032ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import TransformerEncoderLayer, TransformerEncoder, Embedding\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7e82888-c488-4b72-9b13-68c3ff7f56af",
   "metadata": {},
   "outputs": [],
   "source": [
    "wv = Word2Vec.load(\"../checkpoints/model_final.model\").wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80341712-c11f-4d8e-83c9-27d4b48559e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 281217\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0990,  2.4085,  0.3983,  ...,  0.0845,  0.2064,  2.6756],\n",
       "        [ 0.2235,  5.3773,  2.8357,  ..., -4.8849, -5.0111, -2.0209],\n",
       "        [-2.7695,  4.5329,  0.3006,  ..., -5.3204, -3.4041,  0.4088],\n",
       "        ...,\n",
       "        [-1.1284, -0.0572, -2.2218,  ..., -0.6975,  0.8115, -1.0279],\n",
       "        [ 0.6771,  0.1054,  0.1341,  ...,  0.6022, -0.1027, -0.7091],\n",
       "        [-0.8491, -0.9734, -1.2336,  ...,  0.8185, -0.1867, -1.1534]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create embedding layer from gensim embeddings\n",
    "print(wv.vector_size, len(wv))\n",
    "embd = Embedding(len(wv), wv.vector_size)\n",
    "embd.weight.data.copy_(torch.tensor(wv.vectors, dtype=torch.float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ea9c7ca-6488-402a-b9b6-6e1486aafbd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_layer = TransformerEncoderLayer(wv.vector_size, 10, batch_first=True)\n",
    "encoder = TransformerEncoder(encoder_layer, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a244aeea-7524-47da-b7a3-a7ed9fd22dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = random.choices(list(wv.key_to_index.keys()), k=12)\n",
    "t_seq = torch.tensor([wv.key_to_index[item] for item in seq], dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78f6b777-e40d-484f-98b8-be3316023744",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 12, 100]), torch.Size([1, 12, 100]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = embd(t_seq.view(1,-1))\n",
    "encoder(v).shape, v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06af6187-1540-49a8-9d0c-bd81261cccd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 12, 100])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea28195e-c0c7-4109-bc7f-bc6830a81a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask padding: src_key_padding_mask\n",
    "# mask some items: mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "5e0185c7-1391-436a-b00b-cf7f85f3da98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 5)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a,b = batch[2].shape\n",
    "a, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "d5caf656-addf-41f5-beff-abdc180e5630",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[False, False,  True, False,  True],\n",
       "         [False, False,  True, False,  True],\n",
       "         [False, False,  True, False,  True],\n",
       "         [False, False,  True, False,  True],\n",
       "         [False, False,  True, False,  True]],\n",
       "\n",
       "        [[False, False, False, False,  True],\n",
       "         [False, False, False, False,  True],\n",
       "         [False, False, False, False,  True],\n",
       "         [False, False, False, False,  True],\n",
       "         [False, False, False, False,  True]]])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def _generate_attn_mask_single(seq_mask):\n",
    "    \"\"\"\n",
    "        If a BoolTensor is provided, positions with True are not allowed \n",
    "        to attend while False values will be unchanged.\n",
    "        Softmax goes along -1 dimension\n",
    "    \"\"\"\n",
    "    n = seq_mask.shape[0]\n",
    "    mask = torch.zeros((n,n), dtype=torch.bool)\n",
    "    mask[:, seq_mask.nonzero()] = True\n",
    "    return mask\n",
    "\n",
    "def _generate_attn_mask_batch(seq_mask):\n",
    "    bs, n = seq_mask.shape\n",
    "    mask = torch.zeros((bs, n, n), dtype=torch.bool)\n",
    "    nz = seq_mask.nonzero()\n",
    "    a, b = nz[:, 0], nz[:, 1]\n",
    "    mask[a, :, b] = True\n",
    "    return mask\n",
    "\n",
    "def generate_attn_mask(seq_mask):\n",
    "    if len(seq_mask.shape) == 1:\n",
    "        return _generate_attn_mask_single(seq_mask)\n",
    "    elif len(seq_mask.shape) == 2:\n",
    "        return _generate_attn_mask_batch(seq_mask)\n",
    "    else:\n",
    "        assert False, f\"Input should be BATCH_SIZE * SEQ_LEN matrix, got {seq_mask.shape}\"\n",
    "        \n",
    "mask = generate_attn_mask(torch.Tensor([[False, False, True, False, True], [False, False, False, False, True]]))\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "286bdf66-19a7-4f38-935a-6e68f93343de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10, 12, 12]), torch.Size([1, 12, 100]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = torch.Tensor([False] * v.shape[1])\n",
    "attn_mask = generate_attn_mask(mask).repeat(10,1,1)\n",
    "attn_mask.shape, v.shape, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8d36ab2-1f13-41d6-a491-919ee16c196e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_mask.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd8b0f2e-8a17-465e-aea2-529bf2da94cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.4049,  0.9781, -1.9790,  ...,  2.3513,  0.6293,  2.1527],\n",
       "         [-1.1132,  1.9905, -1.0655,  ...,  0.5341,  0.0057,  1.9082],\n",
       "         [ 0.2805, -0.1490, -1.7117,  ...,  0.5807,  0.0717,  1.0083],\n",
       "         ...,\n",
       "         [-1.3863,  2.4944,  0.3424,  ...,  0.8583,  0.8222,  0.4182],\n",
       "         [-1.5273,  1.4244, -0.9384,  ...,  0.4088,  0.3260, -0.5216],\n",
       "         [-0.8199,  0.5492, -0.1732,  ...,  1.3180,  1.1253,  0.8410]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = encoder(v, mask=attn_mask)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "64d4c616-62ca-43a4-8011-fa48e10333d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "\n",
    "class PlaylistDataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, files, playlist_per_file, transform=None):\n",
    "        self.files = files\n",
    "        self.current_file_index = -1\n",
    "        self.data = None\n",
    "        self.ppf = playlist_per_file\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.ppf * len(self.files)\n",
    "    \n",
    "    def _load(self, path):\n",
    "        with open(path, \"r\") as f:\n",
    "            self.data = json.load(f)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        file_index = index // self.ppf\n",
    "        offset = index % self.ppf\n",
    "        if self.current_file_index != file_index:\n",
    "            logging.debug(f\"Loading file {self.files[file_index]}\")\n",
    "            self._load(self.files[file_index])\n",
    "            self.current_file_index = file_index\n",
    "        tracks = self.data[\"playlists\"][offset]\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            tracks = self.transform(tracks)\n",
    "        \n",
    "        return tracks\n",
    "\n",
    "    \n",
    "class Compose:\n",
    "    \n",
    "    def __init__(self, *tfs):\n",
    "        self.tfs = tfs\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        for tf in self.tfs:\n",
    "            x = tf(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "class RemoveUnknownTracks:\n",
    "    \n",
    "    def __init__(self, known_tracks):\n",
    "        kt = known_tracks\n",
    "        if not isinstance(kt, set):\n",
    "            kt = set(kt)\n",
    "        self.kt = kt\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        return [xi for xi in x if xi in self.kt]\n",
    "    \n",
    "    \n",
    "class TrackURI2Idx:\n",
    "    \n",
    "    def __init__(self, uri2idx, offset=0):\n",
    "        self.offset = offset\n",
    "        self.uri2idx = uri2idx\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        return [self.uri2idx[xi] + self.offset for xi in x]\n",
    "    \n",
    "    \n",
    "class ToLongTensor:\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        return torch.LongTensor(x)\n",
    "    \n",
    "class PadOrTrim:\n",
    "    \n",
    "    def __init__(self, pad_token, target_length):\n",
    "        self.token = pad_token\n",
    "        self.t = target_length\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        if len(x) == self.t:\n",
    "            return x\n",
    "        if len(x) < self.t:\n",
    "            return x + [self.token] * (self.t - len(x))\n",
    "        return x[:self.t]\n",
    "    \n",
    "    \n",
    "class MaskTracksTensor:\n",
    "    \n",
    "    def __init__(self, mask_token, padding_token, mask_proba):\n",
    "        self.token = mask_token\n",
    "        self.padding_token = padding_token\n",
    "        self.proba = mask_proba\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        mask = torch.rand(x.shape[0]) < self.proba\n",
    "        padding = x == self.padding_token\n",
    "        # avoid masking padded tracks\n",
    "        mask = mask & (~padding)\n",
    "        x_ = x.clone()\n",
    "        x_[mask] = self.token\n",
    "        return x_, x, mask\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "401d793f-9e3f-4299-8b8d-8984c624c572",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ True, False, False, False])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = torch.BoolTensor([True, False, False, True])\n",
    "pad = torch.BoolTensor([False, False, True, True])\n",
    "\n",
    "mask & (~pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "439e89b4-6aaf-4f77-8cae-7336214af09e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../playlists_data/chunk_0.json',\n",
       " '../playlists_data/chunk_1.json',\n",
       " '../playlists_data/chunk_2.json',\n",
       " '../playlists_data/chunk_3.json',\n",
       " '../playlists_data/chunk_4.json',\n",
       " '../playlists_data/chunk_5.json',\n",
       " '../playlists_data/chunk_6.json',\n",
       " '../playlists_data/chunk_7.json',\n",
       " '../playlists_data/chunk_8.json',\n",
       " '../playlists_data/chunk_9.json',\n",
       " '../playlists_data/chunk_10.json',\n",
       " '../playlists_data/chunk_11.json',\n",
       " '../playlists_data/chunk_12.json',\n",
       " '../playlists_data/chunk_13.json',\n",
       " '../playlists_data/chunk_14.json',\n",
       " '../playlists_data/chunk_15.json',\n",
       " '../playlists_data/chunk_16.json',\n",
       " '../playlists_data/chunk_17.json',\n",
       " '../playlists_data/chunk_18.json',\n",
       " '../playlists_data/chunk_19.json']"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = [f\"../playlists_data/chunk_{i}.json\" for i in range(20)]\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "32ec579d-0321-4bab-a02a-8b0f5db81953",
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD_TOKEN = 0\n",
    "MASK_TOKEN = 1\n",
    "\n",
    "transforms = Compose(\n",
    "    RemoveUnknownTracks(wv.key_to_index.keys()),\n",
    "    TrackURI2Idx(wv.key_to_index, offset=2),\n",
    "    PadOrTrim(PAD_TOKEN, 5),\n",
    "    ToLongTensor(),\n",
    "    MaskTracksTensor(MASK_TOKEN, PAD_TOKEN, .1)\n",
    ")\n",
    "\n",
    "ds = PlaylistDataset(files, 50000, transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "3f099e0f-aa9a-404b-856b-49fc884a775a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "4a7bee8b-d5e1-497f-9856-fdee8cd0a8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = DataLoader(ds, shuffle=False, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "eea83a57-d0db-4b7a-8e52-9748dec9ffc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in dl:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "b1857801-d43f-4651-b7ec-28bf8c01a1bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[  1228,    356,    177,    803,     68],\n",
       "         [   380, 235913,      1, 126095,  10340],\n",
       "         [ 99654, 153183, 140755,  55915,  11900],\n",
       "         [ 31343,  37487, 131362,  38786,  34456],\n",
       "         [  4191,    143,    846, 212700,   1043],\n",
       "         [  1636,     98,      1,   1283,  60442],\n",
       "         [ 11492,  20491, 179673,   2002,   5471],\n",
       "         [ 64637,   3487,   3761,    401,      1],\n",
       "         [ 17164,   7608,      1,  15300,  26847],\n",
       "         [  4898,   4898,  12900,   2189,   2758],\n",
       "         [  3686,    657,    187,    965,    748],\n",
       "         [  6674, 191212,   2463,   5150,   3873],\n",
       "         [  2827,    134,    121,   1838,    586],\n",
       "         [   415,   2215,      1,  82184,   1788],\n",
       "         [     1,   3431,   4127,   3236,   1443],\n",
       "         [  1354,  15557,  11069,      1,   7987],\n",
       "         [ 20766,  33418, 144088,  14677,      1],\n",
       "         [  1332,   3587,      1,    130,      1],\n",
       "         [  5716,  12725,   2210,   2717,    252],\n",
       "         [ 31207,  61419,  26920, 229898,  27663],\n",
       "         [ 12706,   4072,   8396,   2674,     10],\n",
       "         [  2407,   2256,   2694,      1,      1],\n",
       "         [  4676,   8235,   1861,    683,    326],\n",
       "         [ 27794,  25764,  52101,  69121,   4110],\n",
       "         [    58,    102,    620,   2236,   1567],\n",
       "         [ 10734,   1619,   6298,    724,    724],\n",
       "         [ 13256,  29577,   6303,   5227,  26271],\n",
       "         [ 36013,  79277,   3072,   4687,      1],\n",
       "         [   377,   1951,   1688,    748,   6581],\n",
       "         [   882,    328,   5024,   1870,    273],\n",
       "         [143150,  96603, 253169,  92200, 186715],\n",
       "         [   791,    584,   8243,  17717,   1608],\n",
       "         [   352,    222,  14662,  15643,   9468],\n",
       "         [ 11860,  36740,   3119,   7916,     74],\n",
       "         [  6119,      1,     22,   1629,   1558],\n",
       "         [  1821,   4834, 126976, 186349,  52502],\n",
       "         [ 28164,      1,  24728,  63053,      1],\n",
       "         [ 12499, 130328,     36,    332,   1794],\n",
       "         [   476,   1672,    383,   1399,   1245],\n",
       "         [  2171,   1664,    761,    990,    605],\n",
       "         [   213,      1,   1676,     32,      1],\n",
       "         [   794,     41,    398,    752,    178],\n",
       "         [ 22730,   1661,    389,  35689,   3769],\n",
       "         [  5474,    747,   2594,      1,   4159],\n",
       "         [     1,   2435,      1,      1,    402],\n",
       "         [   478,    520,   1714,   2040,   1635],\n",
       "         [ 52773,   6046,   4988,  84917, 245947],\n",
       "         [   316,  95417, 230437,      1,  10224],\n",
       "         [  1659,    964,   2768,      1,      1],\n",
       "         [ 77248,  56198,      1,  27483, 213288],\n",
       "         [    27,      1,    178,    402,      1],\n",
       "         [   112,   1344,  12629,  19708,  18994],\n",
       "         [  5919,   3968,   1537,   4999,   1599],\n",
       "         [   167,   4795,    324,    505,  29286],\n",
       "         [  5038,    457,   6768,  10986,      0],\n",
       "         [   964,   1659,   2062,  26019,   2768],\n",
       "         [  9942,   5167,  25866,   9380,  10053],\n",
       "         [ 18357,   7518,  68531,      1,    795],\n",
       "         [  9040,  58672,  51936,  41392,  34112],\n",
       "         [ 23813,   9135, 191875,   1329,  15615],\n",
       "         [   442,    779,  18654,  16111,   2056],\n",
       "         [ 16116,   1005,    389,   2507,      1],\n",
       "         [    91,      1,   1067,   2777,     34],\n",
       "         [   488,   5619,      1,      1,   5399]]),\n",
       " tensor([[  1228,    356,    177,    803,     68],\n",
       "         [   380, 235913, 225684, 126095,  10340],\n",
       "         [ 99654, 153183, 140755,  55915,  11900],\n",
       "         [ 31343,  37487, 131362,  38786,  34456],\n",
       "         [  4191,    143,    846, 212700,   1043],\n",
       "         [  1636,     98,    919,   1283,  60442],\n",
       "         [ 11492,  20491, 179673,   2002,   5471],\n",
       "         [ 64637,   3487,   3761,    401,  10091],\n",
       "         [ 17164,   7608,  17486,  15300,  26847],\n",
       "         [  4898,   4898,  12900,   2189,   2758],\n",
       "         [  3686,    657,    187,    965,    748],\n",
       "         [  6674, 191212,   2463,   5150,   3873],\n",
       "         [  2827,    134,    121,   1838,    586],\n",
       "         [   415,   2215,   4348,  82184,   1788],\n",
       "         [  7761,   3431,   4127,   3236,   1443],\n",
       "         [  1354,  15557,  11069,   4291,   7987],\n",
       "         [ 20766,  33418, 144088,  14677,  11573],\n",
       "         [  1332,   3587,   6646,    130,    424],\n",
       "         [  5716,  12725,   2210,   2717,    252],\n",
       "         [ 31207,  61419,  26920, 229898,  27663],\n",
       "         [ 12706,   4072,   8396,   2674,     10],\n",
       "         [  2407,   2256,   2694,    578,  23648],\n",
       "         [  4676,   8235,   1861,    683,    326],\n",
       "         [ 27794,  25764,  52101,  69121,   4110],\n",
       "         [    58,    102,    620,   2236,   1567],\n",
       "         [ 10734,   1619,   6298,    724,    724],\n",
       "         [ 13256,  29577,   6303,   5227,  26271],\n",
       "         [ 36013,  79277,   3072,   4687,     43],\n",
       "         [   377,   1951,   1688,    748,   6581],\n",
       "         [   882,    328,   5024,   1870,    273],\n",
       "         [143150,  96603, 253169,  92200, 186715],\n",
       "         [   791,    584,   8243,  17717,   1608],\n",
       "         [   352,    222,  14662,  15643,   9468],\n",
       "         [ 11860,  36740,   3119,   7916,     74],\n",
       "         [  6119,   2951,     22,   1629,   1558],\n",
       "         [  1821,   4834, 126976, 186349,  52502],\n",
       "         [ 28164,  24705,  24728,  63053,   3253],\n",
       "         [ 12499, 130328,     36,    332,   1794],\n",
       "         [   476,   1672,    383,   1399,   1245],\n",
       "         [  2171,   1664,    761,    990,    605],\n",
       "         [   213,   2027,   1676,     32,     83],\n",
       "         [   794,     41,    398,    752,    178],\n",
       "         [ 22730,   1661,    389,  35689,   3769],\n",
       "         [  5474,    747,   2594,  23273,   4159],\n",
       "         [  2020,   2435,   4496, 154467,    402],\n",
       "         [   478,    520,   1714,   2040,   1635],\n",
       "         [ 52773,   6046,   4988,  84917, 245947],\n",
       "         [   316,  95417, 230437,  29600,  10224],\n",
       "         [  1659,    964,   2768,   4245,  43765],\n",
       "         [ 77248,  56198,  74876,  27483, 213288],\n",
       "         [    27,    148,    178,    402,    225],\n",
       "         [   112,   1344,  12629,  19708,  18994],\n",
       "         [  5919,   3968,   1537,   4999,   1599],\n",
       "         [   167,   4795,    324,    505,  29286],\n",
       "         [  5038,    457,   6768,  10986,      0],\n",
       "         [   964,   1659,   2062,  26019,   2768],\n",
       "         [  9942,   5167,  25866,   9380,  10053],\n",
       "         [ 18357,   7518,  68531,  10150,    795],\n",
       "         [  9040,  58672,  51936,  41392,  34112],\n",
       "         [ 23813,   9135, 191875,   1329,  15615],\n",
       "         [   442,    779,  18654,  16111,   2056],\n",
       "         [ 16116,   1005,    389,   2507,    357],\n",
       "         [    91,    385,   1067,   2777,     34],\n",
       "         [   488,   5619,   3578,    214,   5399]]),\n",
       " tensor([[False, False, False, False, False],\n",
       "         [False, False,  True, False, False],\n",
       "         [False, False, False, False, False],\n",
       "         [False, False, False, False, False],\n",
       "         [False, False, False, False, False],\n",
       "         [False, False,  True, False, False],\n",
       "         [False, False, False, False, False],\n",
       "         [False, False, False, False,  True],\n",
       "         [False, False,  True, False, False],\n",
       "         [False, False, False, False, False],\n",
       "         [False, False, False, False, False],\n",
       "         [False, False, False, False, False],\n",
       "         [False, False, False, False, False],\n",
       "         [False, False,  True, False, False],\n",
       "         [ True, False, False, False, False],\n",
       "         [False, False, False,  True, False],\n",
       "         [False, False, False, False,  True],\n",
       "         [False, False,  True, False,  True],\n",
       "         [False, False, False, False, False],\n",
       "         [False, False, False, False, False],\n",
       "         [False, False, False, False, False],\n",
       "         [False, False, False,  True,  True],\n",
       "         [False, False, False, False, False],\n",
       "         [False, False, False, False, False],\n",
       "         [False, False, False, False, False],\n",
       "         [False, False, False, False, False],\n",
       "         [False, False, False, False, False],\n",
       "         [False, False, False, False,  True],\n",
       "         [False, False, False, False, False],\n",
       "         [False, False, False, False, False],\n",
       "         [False, False, False, False, False],\n",
       "         [False, False, False, False, False],\n",
       "         [False, False, False, False, False],\n",
       "         [False, False, False, False, False],\n",
       "         [False,  True, False, False, False],\n",
       "         [False, False, False, False, False],\n",
       "         [False,  True, False, False,  True],\n",
       "         [False, False, False, False, False],\n",
       "         [False, False, False, False, False],\n",
       "         [False, False, False, False, False],\n",
       "         [False,  True, False, False,  True],\n",
       "         [False, False, False, False, False],\n",
       "         [False, False, False, False, False],\n",
       "         [False, False, False,  True, False],\n",
       "         [ True, False,  True,  True, False],\n",
       "         [False, False, False, False, False],\n",
       "         [False, False, False, False, False],\n",
       "         [False, False, False,  True, False],\n",
       "         [False, False, False,  True,  True],\n",
       "         [False, False,  True, False, False],\n",
       "         [False,  True, False, False,  True],\n",
       "         [False, False, False, False, False],\n",
       "         [False, False, False, False, False],\n",
       "         [False, False, False, False, False],\n",
       "         [False, False, False, False, False],\n",
       "         [False, False, False, False, False],\n",
       "         [False, False, False, False, False],\n",
       "         [False, False, False,  True, False],\n",
       "         [False, False, False, False, False],\n",
       "         [False, False, False, False, False],\n",
       "         [False, False, False, False, False],\n",
       "         [False, False, False, False,  True],\n",
       "         [False,  True, False, False, False],\n",
       "         [False, False,  True,  True, False]])]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "865ec918-0d54-461f-9212-cfa280b26cc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 5, 100])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embd(batch).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "111cf543-42a7-48f8-9274-a3d809807dcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  1227,    355,    176,    802,     67],\n",
       "        [   379, 235912, 225683, 126094,  10339],\n",
       "        [ 99653, 153182, 140754,  55914,  11899],\n",
       "        [ 31342,  37486, 131361,  38785,  34455],\n",
       "        [  4190,    142,    845, 212699,   1042],\n",
       "        [  1635,     97,    918,   1282,  60441],\n",
       "        [ 11491,  20490, 179672,   2001,   5470],\n",
       "        [ 64636,   3486,   3760,    400,  10090],\n",
       "        [ 17163,   7607,  17485,  15299,  26846],\n",
       "        [  4897,   4897,  12899,   2188,   2757],\n",
       "        [  3685,    656,    186,    964,    747],\n",
       "        [  6673, 191211,   2462,   5149,   3872],\n",
       "        [  2826,    133,    120,   1837,    585],\n",
       "        [   414,   2214,   4347,  82183,   1787],\n",
       "        [  7760,   3430,   4126,   3235,   1442],\n",
       "        [  1353,  15556,  11068,   4290,   7986],\n",
       "        [ 20765,  33417, 144087,  14676,  11572],\n",
       "        [  1331,   3586,   6645,    129,    423],\n",
       "        [  5715,  12724,   2209,   2716,    251],\n",
       "        [ 31206,  61418,  26919, 229897,  27662],\n",
       "        [ 12705,   4071,   8395,   2673,      9],\n",
       "        [  2406,   2255,   2693,    577,  23647],\n",
       "        [  4675,   8234,   1860,    682,    325],\n",
       "        [ 27793,  25763,  52100,  69120,   4109],\n",
       "        [    57,    101,    619,   2235,   1566],\n",
       "        [ 10733,   1618,   6297,    723,    723],\n",
       "        [ 13255,  29576,   6302,   5226,  26270],\n",
       "        [ 36012,  79276,   3071,   4686,     42],\n",
       "        [   376,   1950,   1687,    747,   6580],\n",
       "        [   881,    327,   5023,   1869,    272],\n",
       "        [143149,  96602, 253168,  92199, 186714],\n",
       "        [   790,    583,   8242,  17716,   1607],\n",
       "        [   351,    221,  14661,  15642,   9467],\n",
       "        [ 11859,  36739,   3118,   7915,     73],\n",
       "        [  6118,   2950,     21,   1628,   1557],\n",
       "        [  1820,   4833, 126975, 186348,  52501],\n",
       "        [ 28163,  24704,  24727,  63052,   3252],\n",
       "        [ 12498, 130327,     35,    331,   1793],\n",
       "        [   475,   1671,    382,   1398,   1244],\n",
       "        [  2170,   1663,    760,    989,    604],\n",
       "        [   212,   2026,   1675,     31,     82],\n",
       "        [   793,     40,    397,    751,    177],\n",
       "        [ 22729,   1660,    388,  35688,   3768],\n",
       "        [  5473,    746,   2593,  23272,   4158],\n",
       "        [  2019,   2434,   4495, 154466,    401],\n",
       "        [   477,    519,   1713,   2039,   1634],\n",
       "        [ 52772,   6045,   4987,  84916, 245946],\n",
       "        [   315,  95416, 230436,  29599,  10223],\n",
       "        [  1658,    963,   2767,   4244,  43764],\n",
       "        [ 77247,  56197,  74875,  27482, 213287],\n",
       "        [    26,    147,    177,    401,    224],\n",
       "        [   111,   1343,  12628,  19707,  18993],\n",
       "        [  5918,   3967,   1536,   4998,   1598],\n",
       "        [   166,   4794,    323,    504,  29285],\n",
       "        [  5037,    456,   6767,  10985,      0],\n",
       "        [   963,   1658,   2061,  26018,   2767],\n",
       "        [  9941,   5166,  25865,   9379,  10052],\n",
       "        [ 18356,   7517,  68530,  10149,    794],\n",
       "        [  9039,  58671,  51935,  41391,  34111],\n",
       "        [ 23812,   9134, 191874,   1328,  15614],\n",
       "        [   441,    778,  18653,  16110,   2055],\n",
       "        [ 16115,   1004,    388,   2506,    356],\n",
       "        [    90,    384,   1066,   2776,     33],\n",
       "        [   487,   5618,   3577,    213,   5398]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f5680137-544f-40bd-850e-a04cc37cdccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightning.pytorch as pl\n",
    "\n",
    "\n",
    "# TODO: add final linear layer\n",
    "\n",
    "GELU = nn.GELU()\n",
    "\n",
    "class TransRec(pl.LightningModule):\n",
    "    \n",
    "    def __init__(self, wv_model, n_head, layer_kwargs={}, enc_kwargs={}):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embd = Embedding(len(wv_model)+2, wv_model.vector_size) # +2 for <PAD> and <MASK> tokens\n",
    "        self.embd.weight.data[2:].copy_(torch.tensor(wv_model.vectors, dtype=torch.float))\n",
    "        self.embd.requires_grad_ = False\n",
    "        \n",
    "        encoder_layer = TransformerEncoderLayer(wv_model.vector_size, batch_first=True, \\\n",
    "                                                nhead=n_head, **layer_kwargs)\n",
    "        self.encoder = TransformerEncoder(encoder_layer, **enc_kwargs)\n",
    "        self.linear = nn.Linear(wv_model.vector_size, wv_model.vector_size, bias=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.embd(x)\n",
    "        x = self.encoder(x)\n",
    "        z = GELU(self.linear(x))\n",
    "        bs, seq_len, embd_dim = x.shape\n",
    "        num_tokens = self.embd.weight.shape[0]\n",
    "        logits = torch.matmul(self.embd.weight, z.view(-1, embd_dim).T) \\\n",
    "                .view(num_tokens, bs, -1)\n",
    "        return logits.softmax(dim=0)\n",
    "    \n",
    "    \n",
    "    def _build_attn_mask()\n",
    "        \n",
    "        \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y, mask = batch\n",
    "        padding_mask = x == PAD_TOKEN\n",
    "        \n",
    "        \n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a0ea6efc-a4f2-4e98-a230-b207d5776d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = TransRec(wv, n_head=10, enc_kwargs={\"num_layers\": 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a938f1af-14af-4787-bfbd-ddbd98494814",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([281219, 64, 5])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = tr(batch)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c2dc5379-90ab-42ab-9010-a421b5748d18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 5])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.argmax(dim=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "def7c074-fdf4-42a4-825e-c2eb600ad5db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(320.0490, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.softmax(dim=0).sum(dim=0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce1506f-6a5b-42eb-a030-60c1d3a95df4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
