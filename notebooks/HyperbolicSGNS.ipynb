{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "868c86a0-d794-46f3-b3c3-50f82698d9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx\n",
    "import geoopt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import random\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d40cb0fa-5876-4466-8fc4-bb0e6a45892e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ManifoldEmbedding(nn.Module):\n",
    "    \n",
    "    def __init__(self, manifold, num_embeddings, embedding_dim, dtype=torch.double, requires_grad=True, weights=None):\n",
    "        super().__init__()\n",
    "        if dtype != torch.double:\n",
    "            logging.warning(\"Double precision is recommended for embeddings on manifold\")\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.num_embeddings = num_embeddings\n",
    "        self._manifold = manifold\n",
    "        if weights is None:\n",
    "            data = torch.zeros((num_embeddings, embedding_dim), dtype=dtype)\n",
    "            data = geoopt.ManifoldTensor(data, manifold=self._manifold)\n",
    "            self.w = geoopt.ManifoldParameter(data, requires_grad=requires_grad)\n",
    "            self.reset_parameters()\n",
    "        else:\n",
    "            raise NotImplementedError()\n",
    "            \n",
    "    def forward(self, x):\n",
    "        s0 = x.shape\n",
    "        ws = self.w[x.view(-1)]\n",
    "        return ws.view(*s0, self.embedding_dim)\n",
    "    \n",
    "    def reset_parameters(self) -> None:\n",
    "        nn.init.normal_(self.w.data)\n",
    "        self.w.data[:] = self._manifold.retr(torch.zeros(self.embedding_dim), self.w.data)\n",
    "        \n",
    "        \n",
    "class LorentzEmbedding(ManifoldEmbedding):\n",
    "    \n",
    "    def __init__(self, num_embeddings, embedding_dim, k=1.0, **kwargs):\n",
    "        manifold = geoopt.manifolds.Lorentz(k, learnable=False)\n",
    "        super().__init__(manifold, num_embeddings, embedding_dim, **kwargs)\n",
    "        \n",
    "        \n",
    "class LorentzSkipGram(nn.Module):\n",
    "    \n",
    "    def __init__(self, theta, k=1.0):\n",
    "        super().__init__()\n",
    "        self.theta = theta\n",
    "        self._manifold = geoopt.manifolds.Lorentz(k)\n",
    "        self.x0 = torch.zeros(10)\n",
    "        \n",
    "    def forward(self, a, b):\n",
    "        return self._manifold.inner(self.x0, a, b)\n",
    "    \n",
    "\n",
    "class SGNSLoss(nn.Module):\n",
    "    \n",
    "    def __init__(self, reduction=\"mean\"):\n",
    "        super().__init__()\n",
    "        self.reduction = reduction\n",
    "        \n",
    "    def forward(self, y_, y):\n",
    "        y.masked_fill_(y == 0, -1)\n",
    "        loss = torch.log(torch.sigmoid(y*y_))\n",
    "        if self.reduction is None:\n",
    "            return loss\n",
    "        elif self.reduction == \"mean\":\n",
    "            return loss.mean()\n",
    "        elif self.rediction == \"sum\":\n",
    "            return loss.sum()\n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "980f3464-66c3-4375-b51b-5ebaafaf367e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightning as pl\n",
    "\n",
    "\n",
    "class Model(pl.LightningModule):\n",
    "    \n",
    "    def __init__(self, num_embeddings, embedding_dim, theta, k=1.0):\n",
    "        super().__init__()\n",
    "        self.embd = LorentzEmbedding(num_embeddings, embedding_dim, k)\n",
    "        self.sg = LorentzSkipGram(theta, k)\n",
    "        self.loss_fn = SGNSLoss()\n",
    "        \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        e1, e2 = x[:, 0], x[:, 1]\n",
    "        z = self.sg(e1, e2)\n",
    "        return self.loss_fn(z, y)\n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = geoopt.optim.RiemannianAdam(self.parameters(), 1e-3)\n",
    "        return optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912638b6-f162-45b5-9639-2165cd6fbe0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGNSDataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, files, playlist_per_file, window=5, transform=None):\n",
    "        super().__init__()\n",
    "        self.files = files\n",
    "        self.current_file_index = -1\n",
    "        self.data = None\n",
    "        self.transform = transform\n",
    "        self.ppf = playlist_per_file\n",
    "        self.window = window\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.ppf * len(self.files)\n",
    "        \n",
    "    def _load(self, path):\n",
    "        with open(path, \"r\") as f:\n",
    "            self.data = json.load(f)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        file_index = index // self.ppf\n",
    "        offset = index % self.ppf\n",
    "        if self.current_file_index != file_index:\n",
    "            logging.debug(f\"Loading file {self.files[file_index]}\")\n",
    "            self._load(self.files[file_index])\n",
    "            self.current_file_index = file_index\n",
    "        tracks = self.data[\"playlists\"][offset]\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            tracks = self.transform(tracks)\n",
    "        \n",
    "        return tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e8b42444-d64c-4476-8a77-a311c128bcae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def skip_gram(x, i, w):\n",
    "    return x[i], x[max(0, i-w):i] + x[i+1:i+w+1]\n",
    "\n",
    "class SkipGramWithNegativeSampling:\n",
    "    \n",
    "    def __init__(self, window, vocabulary, negative=5, negative_probs=None):\n",
    "        self.window = window\n",
    "        self.vocabulary = vocabulary\n",
    "        self.negative = negative\n",
    "        self.negative_probs = negative_probs\n",
    "        \n",
    "    def sample_negatives(self, query):\n",
    "        assert self.negative_probs is None, \"Weighted sampling not implemented yet!\"\n",
    "        items = set(query)\n",
    "        randoms = random.choices(self.vocabulary, k=len(items)*self.negative)\n",
    "        return zip(list(items)*self.negative, randoms)\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        grams = [skip_gram(x, i, self.window) for i in range(len(x))]\n",
    "        batches = [[w,c] for w,context in grams for c in context]\n",
    "        negatives = list(self.sample_negatives(x))\n",
    "        labels = [1] * len(batches) + [0] * len(negatives)\n",
    "        return batches + negatives, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8a497b8d-d87c-4323-9af6-90c43e3eac66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'l'] 1\n",
      "['a', 'm'] 1\n",
      "['l', 'a'] 1\n",
      "['l', 'm'] 1\n",
      "['l', 'a'] 1\n",
      "['m', 'a'] 1\n",
      "['m', 'l'] 1\n",
      "['m', 'a'] 1\n",
      "['m', 'p'] 1\n",
      "['a', 'l'] 1\n",
      "['a', 'm'] 1\n",
      "['a', 'p'] 1\n",
      "['a', 'a'] 1\n",
      "['p', 'm'] 1\n",
      "['p', 'a'] 1\n",
      "['p', 'a'] 1\n",
      "['p', 'p'] 1\n",
      "['a', 'a'] 1\n",
      "['a', 'p'] 1\n",
      "['a', 'p'] 1\n",
      "['a', 'r'] 1\n",
      "['p', 'p'] 1\n",
      "['p', 'a'] 1\n",
      "['p', 'r'] 1\n",
      "['p', 'i'] 1\n",
      "['r', 'a'] 1\n",
      "['r', 'p'] 1\n",
      "['r', 'i'] 1\n",
      "['r', 'k'] 1\n",
      "['i', 'p'] 1\n",
      "['i', 'r'] 1\n",
      "['i', 'k'] 1\n",
      "['i', 'a'] 1\n",
      "['k', 'r'] 1\n",
      "['k', 'i'] 1\n",
      "['k', 'a'] 1\n",
      "['a', 'i'] 1\n",
      "['a', 'k'] 1\n",
      "('a', 'd') 0\n",
      "('r', 'u') 0\n",
      "('m', 'd') 0\n",
      "('p', 'k') 0\n",
      "('i', 'e') 0\n",
      "('k', 'y') 0\n",
      "('l', 'e') 0\n",
      "('a', 'r') 0\n",
      "('r', 'f') 0\n",
      "('m', 'o') 0\n",
      "('p', 'p') 0\n",
      "('i', 'z') 0\n",
      "('k', 'x') 0\n",
      "('l', 'f') 0\n",
      "('a', 's') 0\n",
      "('r', 'x') 0\n",
      "('m', 'u') 0\n",
      "('p', 'r') 0\n",
      "('i', 'i') 0\n",
      "('k', 'c') 0\n",
      "('l', 'c') 0\n",
      "('a', 'i') 0\n",
      "('r', 'k') 0\n",
      "('m', 'i') 0\n",
      "('p', 'k') 0\n",
      "('i', 'k') 0\n",
      "('k', 'g') 0\n",
      "('l', 'e') 0\n"
     ]
    }
   ],
   "source": [
    "vocab = list(\"abcdefghijklmnopqrstuvxyz\")\n",
    "sg = SkipGramWithNegativeSampling(2, vocab, negative=4)\n",
    "for a,b in zip(*sg(\"almapaprika\")):\n",
    "    print(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f732d0-726d-4c8e-8791-b03d354827a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
